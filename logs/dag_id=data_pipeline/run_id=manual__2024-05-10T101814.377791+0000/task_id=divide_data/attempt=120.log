[2024-05-10T13:32:47.159+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-05-10T13:32:47.190+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: data_pipeline.divide_data manual__2024-05-10T10:18:14.377791+00:00 [queued]>
[2024-05-10T13:32:47.197+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: data_pipeline.divide_data manual__2024-05-10T10:18:14.377791+00:00 [queued]>
[2024-05-10T13:32:47.198+0000] {taskinstance.py:2306} INFO - Starting attempt 120 of 123
[2024-05-10T13:32:47.209+0000] {taskinstance.py:2330} INFO - Executing <Task(PythonOperator): divide_data> on 2024-05-10 10:18:14.377791+00:00
[2024-05-10T13:32:47.215+0000] {logging_mixin.py:188} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61 DeprecationWarning: This process (pid=9520) is multi-threaded, use of fork() may lead to deadlocks in the child.
[2024-05-10T13:32:47.216+0000] {standard_task_runner.py:63} INFO - Started process 9528 to run task
[2024-05-10T13:32:47.215+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'data_pipeline', 'divide_data', 'manual__2024-05-10T10:18:14.377791+00:00', '--job-id', '549', '--raw', '--subdir', 'DAGS_FOLDER/main_dag.py', '--cfg-path', '/tmp/tmpz9jcm6v2']
[2024-05-10T13:32:47.217+0000] {standard_task_runner.py:91} INFO - Job 549: Subtask divide_data
[2024-05-10T13:32:47.228+0000] {logging_mixin.py:188} WARNING - /home/***/.local/lib/python3.12/site-packages/***/settings.py:195 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2024-05-10T13:32:47.253+0000] {task_command.py:426} INFO - Running <TaskInstance: data_pipeline.divide_data manual__2024-05-10T10:18:14.377791+00:00 [running]> on host dbfcb70dcca2
[2024-05-10T13:32:47.321+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='data_pipeline' AIRFLOW_CTX_TASK_ID='divide_data' AIRFLOW_CTX_EXECUTION_DATE='2024-05-10T10:18:14.377791+00:00' AIRFLOW_CTX_TRY_NUMBER='120' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-05-10T10:18:14.377791+00:00'
[2024-05-10T13:32:47.322+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-05-10T13:32:51.965+0000] {logging_mixin.py:188} INFO -                                                    title
0      Public health and international epidemiology f...
0      Public health and international epidemiology f...
0      Public health and international epidemiology f...
0      Public health and international epidemiology f...
0      Public health and international epidemiology f...
...                                                  ...
22114  Study of the liquid film forming apparatus as ...
22116  Towards 5G cellular  Understanding 3D in build...
22117  Modeling of root reinforced soil slope under r...
22118  Production of massoia lactone by Aureobasidium...
22120  Two dimensional modeling of the oxidative coup...

[230310 rows x 1 columns]
[2024-05-10T13:32:51.992+0000] {python.py:237} INFO - Done. Returned value was: None
[2024-05-10T13:32:51.993+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-05-10T13:32:51.999+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=data_pipeline, task_id=divide_data, run_id=manual__2024-05-10T10:18:14.377791+00:00, execution_date=20240510T101814, start_date=20240510T133247, end_date=20240510T133251
[2024-05-10T13:32:52.045+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-05-10T13:32:52.058+0000] {taskinstance.py:3498} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-05-10T13:32:52.060+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
