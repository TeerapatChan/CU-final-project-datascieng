[2024-05-10T12:29:06.180+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-05-10T12:29:06.204+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: data_pipeline.divide_data manual__2024-05-10T10:18:14.377791+00:00 [queued]>
[2024-05-10T12:29:06.211+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: data_pipeline.divide_data manual__2024-05-10T10:18:14.377791+00:00 [queued]>
[2024-05-10T12:29:06.212+0000] {taskinstance.py:2306} INFO - Starting attempt 77 of 80
[2024-05-10T12:29:06.224+0000] {taskinstance.py:2330} INFO - Executing <Task(PythonOperator): divide_data> on 2024-05-10 10:18:14.377791+00:00
[2024-05-10T12:29:06.230+0000] {logging_mixin.py:188} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61 DeprecationWarning: This process (pid=6483) is multi-threaded, use of fork() may lead to deadlocks in the child.
[2024-05-10T12:29:06.231+0000] {standard_task_runner.py:63} INFO - Started process 6485 to run task
[2024-05-10T12:29:06.231+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'data_pipeline', 'divide_data', 'manual__2024-05-10T10:18:14.377791+00:00', '--job-id', '469', '--raw', '--subdir', 'DAGS_FOLDER/main_dag.py', '--cfg-path', '/tmp/tmp6ee8j69f']
[2024-05-10T12:29:06.233+0000] {standard_task_runner.py:91} INFO - Job 469: Subtask divide_data
[2024-05-10T12:29:06.243+0000] {logging_mixin.py:188} WARNING - /home/***/.local/lib/python3.12/site-packages/***/settings.py:195 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2024-05-10T12:29:06.268+0000] {task_command.py:426} INFO - Running <TaskInstance: data_pipeline.divide_data manual__2024-05-10T10:18:14.377791+00:00 [running]> on host dbfcb70dcca2
[2024-05-10T12:29:06.332+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='data_pipeline' AIRFLOW_CTX_TASK_ID='divide_data' AIRFLOW_CTX_EXECUTION_DATE='2024-05-10T10:18:14.377791+00:00' AIRFLOW_CTX_TRY_NUMBER='77' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-05-10T10:18:14.377791+00:00'
[2024-05-10T12:29:06.333+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-05-10T12:29:07.824+0000] {logging_mixin.py:188} INFO -                                                    title  ... publication_year
0      Parametric study of hydrogen production via so...  ...                 
1      Parametric study of hydrogen production via so...  ...                 
2      Parametric study of hydrogen production via so...  ...                 
3      Parametric study of hydrogen production via so...  ...                 
4      Parametric study of hydrogen production via so...  ...                 
...                                                  ...  ...              ...
84010  Towards 5G cellular  Understanding 3D in build...  ...                 
84011  Modeling of root reinforced soil slope under r...  ...                 
84012  Production of massoia lactone by Aureobasidium...  ...                 
84013  Efficiencies of NF and RO membranes on pharmac...  ...                 
84014  Two dimensional modeling of the oxidative coup...  ...                 

[84015 rows x 3 columns]
[2024-05-10T12:29:07.943+0000] {logging_mixin.py:188} INFO - 0        Parametric study of hydrogen production via so...
1        Parametric study of hydrogen production via so...
2        Parametric study of hydrogen production via so...
3        Parametric study of hydrogen production via so...
4        Parametric study of hydrogen production via so...
                               ...                        
84010    Towards 5G cellular  Understanding 3D in build...
84011    Modeling of root reinforced soil slope under r...
84012    Production of massoia lactone by Aureobasidium...
84013    Efficiencies of NF and RO membranes on pharmac...
84014    Two dimensional modeling of the oxidative coup...
Name: title, Length: 84015, dtype: object
[2024-05-10T12:29:08.015+0000] {logging_mixin.py:188} INFO - 0                                Circulating fluidized bed
1                             Computational fluid dynamics
2                                   Multiphase flow models
3                                                    Riser
4                Sorption enhanced steam methane reforming
                               ...                        
84010    5G   Architecture   Control  user plane   Femt...
84011    Centrifuge modeling   Landslides   Seepage ana...
84012    Aureobasidium pullulans   fragrant biosurfacta...
84013    Carbamazepine   Membrane fouling   Nanofiltrat...
84014    Fixed bed reactor   Gas hour space velocity (G...
Name: keyword, Length: 84015, dtype: object
[2024-05-10T12:29:08.069+0000] {logging_mixin.py:188} INFO - 0         
1         
2         
3         
4         
        ..
84010     
84011     
84012     
84013     
84014     
Name: publication_year, Length: 84015, dtype: object
[2024-05-10T12:29:08.072+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-05-10T12:29:08.073+0000] {taskinstance.py:2905} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 465, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 432, in _execute_callable
    return execute_callable(context=context, **execute_callable_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 400, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/python.py", line 235, in execute
    return_value = self.execute_callable()
                   ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/python.py", line 252, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/tasks/divide_data.py", line 33, in divide_data
    title_keywords_year(df, file_path_to_upload)
  File "/opt/airflow/dags/tasks/divide_data.py", line 79, in title_keywords_year
    new_df.to_csv(file_path_to_upload + 'title_keywords.csv', index=False)
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/core/generic.py", line 3902, in to_csv
    return DataFrameRenderer(formatter).to_csv(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/formats/format.py", line 1152, in to_csv
    csv_formatter.save()
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/formats/csvs.py", line 247, in save
    with get_handle(
         ^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/common.py", line 863, in get_handle
    handle = open(
             ^^^^^
PermissionError: [Errno 13] Permission denied: '/opt/airflow/data/title_keywords.csv'
[2024-05-10T12:29:08.083+0000] {taskinstance.py:1206} INFO - Marking task as UP_FOR_RETRY. dag_id=data_pipeline, task_id=divide_data, run_id=manual__2024-05-10T10:18:14.377791+00:00, execution_date=20240510T101814, start_date=20240510T122906, end_date=20240510T122908
[2024-05-10T12:29:08.091+0000] {standard_task_runner.py:110} ERROR - Failed to execute job 469 for task divide_data ([Errno 13] Permission denied: '/opt/airflow/data/title_keywords.csv'; 6485)
[2024-05-10T12:29:08.131+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 1
[2024-05-10T12:29:08.147+0000] {taskinstance.py:3498} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-05-10T12:29:08.149+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
